{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac64f10c",
   "metadata": {},
   "source": [
    "# Twitter NLP Sentiment Classifier\n",
    "\n",
    "This notebook builds a simple NLP model to classify tweets as positive, neutral, or negative using the [Twitter140 dataset](https://www.kaggle.com/datasets/kazanova/sentiment140)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0155e82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import basic core libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d080874a",
   "metadata": {},
   "source": [
    "---\n",
    "### 1. Data Preprocessing ðŸ”¨\n",
    "\n",
    "#### Steps ðŸ“„:\n",
    "- Load and inspect Sentiment140 dataset\n",
    "\n",
    "- Clean raw tweet text\n",
    "\n",
    "- Normalize case and remove stopwords\n",
    "\n",
    "- Split into training, validation, and testing sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340513be",
   "metadata": {},
   "source": [
    "We'll begin by loading our dataframe and exploring the dataset to get an understanding of its structure and the distribution of sentiment labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "164a744d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0           1                             2         3                4  \\\n",
      "0  0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY  _TheSpecialOne_   \n",
      "1  0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY    scotthamilton   \n",
      "2  0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY         mattycus   \n",
      "3  0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          ElleCTF   \n",
      "4  0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY           Karoli   \n",
      "\n",
      "                                                   5  \n",
      "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
      "1  is upset that he can't update his Facebook by ...  \n",
      "2  @Kenichan I dived many times for the ball. Man...  \n",
      "3    my whole body feels itchy and like its on fire   \n",
      "4  @nationwideclass no, it's not behaving at all....  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0\n",
       "0    800000\n",
       "4    800000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/Sentiment140.csv\", encoding=\"latin-1\", header=None)\n",
    "\n",
    "print(df.head())\n",
    "df[0].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657516a6",
   "metadata": {},
   "source": [
    "We are only going to be using the sentiment and text, which are found in column 1 and 5 respectively.<br/>\n",
    "The sentiment is distributed evenly between 0 (negative) and 4 (positive).<br/>\n",
    "It is also clear that the text will need some cleaning (tags, urls, special characters, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce3302c",
   "metadata": {},
   "source": [
    "Lets label our columns and grab the ones we want. <br/>\n",
    "We'll also map all 4s to 1 for binary simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "64caf399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sentiment                                               text\n",
      "0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
      "1          0  is upset that he can't update his Facebook by ...\n",
      "2          0  @Kenichan I dived many times for the ball. Man...\n",
      "3          0    my whole body feels itchy and like its on fire \n",
      "4          0  @nationwideclass no, it's not behaving at all....\n",
      "sentiment\n",
      "0    800000\n",
      "1    800000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df.columns = [\"sentiment\", \"id\", \"date\", \"flag\", \"user\", \"text\"]\n",
    "df = df[[\"sentiment\", \"text\"]]\n",
    "\n",
    "df[\"sentiment\"] = df[\"sentiment\"].replace({4:1})\n",
    "\n",
    "print(df.head())\n",
    "print(df[\"sentiment\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf91ea8",
   "metadata": {},
   "source": [
    "Next we'll use the regular expressions module and NLTK library to clean the tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "90fcaf54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\theli\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        thats bummer shoulda got david carr third day\n",
      "1    upset cant update facebook texting might cry r...\n",
      "2    dived many times ball managed save rest go bounds\n",
      "3                     whole body feels itchy like fire\n",
      "4                             behaving im mad cant see\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from tracemalloc import stop\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "def clean_tweets(text):\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text)\n",
    "    text = re.sub(r\"@\\w+\", \"\", text)\n",
    "    text = re.sub(r\"#\\w+\", \"\", text)\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)\n",
    "    text = text.lower().strip().split()\n",
    "    text = [word for word in text if word not in stop_words]\n",
    "    return \" \".join(text)\n",
    "\n",
    "df[\"text\"] = df[\"text\"].apply(clean_tweets)\n",
    "print (df[\"text\"].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73994a60",
   "metadata": {},
   "source": [
    "Now we can split the data into train, validation, and test using stratified sampling to ensure fair evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d7f62d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train split: sentiment\n",
      "1    0.5\n",
      "0    0.5\n",
      "Name: proportion, dtype: float64\n",
      "validation split: sentiment\n",
      "0    0.5\n",
      "1    0.5\n",
      "Name: proportion, dtype: float64\n",
      "test split: sentiment\n",
      "0    0.5\n",
      "1    0.5\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_trainandval, df_test = train_test_split(df, test_size=0.1, stratify=df[\"sentiment\"], random_state=1)\n",
    "\n",
    "df_train, df_val = train_test_split(df_trainandval, test_size=0.1, stratify=df_trainandval[\"sentiment\"], random_state=1)\n",
    "\n",
    "print(f\"train split: {df_train['sentiment'].value_counts(normalize=True)}\")\n",
    "print(f\"validation split: {df_val['sentiment'].value_counts(normalize=True)}\")\n",
    "print(f\"test split: {df_test['sentiment'].value_counts(normalize=True)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bc3609",
   "metadata": {},
   "source": [
    "### 2. Classical ML Approach ðŸ’»"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4682b6f",
   "metadata": {},
   "source": [
    "### 3. Deep Learning Approach ðŸ§ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac307585",
   "metadata": {},
   "source": [
    "### 4. Comparisons and Conclusions ðŸ’­"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
