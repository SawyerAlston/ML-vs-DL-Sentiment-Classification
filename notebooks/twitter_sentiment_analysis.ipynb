{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac64f10c",
   "metadata": {},
   "source": [
    "# Twitter NLP Sentiment Classifier\n",
    "\n",
    "This notebook builds a simple NLP model to classify tweets as positive, neutral, or negative using the [Twitter140 dataset](https://www.kaggle.com/datasets/kazanova/sentiment140)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "0155e82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import basic core libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d080874a",
   "metadata": {},
   "source": [
    "---\n",
    "### 1. Data Preprocessing ðŸ”¨\n",
    "\n",
    "#### Steps ðŸ“„:\n",
    "- Load and inspect Sentiment140 dataset\n",
    "\n",
    "- Split into training, validation, and testing sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340513be",
   "metadata": {},
   "source": [
    "We'll begin by loading our dataframe and exploring the dataset to get an understanding of its structure and the distribution of sentiment labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "164a744d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0           1                             2         3                4  \\\n",
      "0  0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY  _TheSpecialOne_   \n",
      "1  0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY    scotthamilton   \n",
      "2  0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY         mattycus   \n",
      "3  0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          ElleCTF   \n",
      "4  0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY           Karoli   \n",
      "\n",
      "                                                   5  \n",
      "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
      "1  is upset that he can't update his Facebook by ...  \n",
      "2  @Kenichan I dived many times for the ball. Man...  \n",
      "3    my whole body feels itchy and like its on fire   \n",
      "4  @nationwideclass no, it's not behaving at all....  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0\n",
       "0    800000\n",
       "4    800000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/Sentiment140.csv\", encoding=\"latin-1\", header=None)\n",
    "\n",
    "print(df.head())\n",
    "df[0].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657516a6",
   "metadata": {},
   "source": [
    "We are only going to be using the sentiment and text, which are found in column 1 and 5 respectively.<br/>\n",
    "The sentiment is distributed evenly between 0 (negative) and 4 (positive).<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce3302c",
   "metadata": {},
   "source": [
    "Lets label our columns and grab the ones we want. <br/>\n",
    "We'll also map all 4s to 1 for binary simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "64caf399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sentiment                                               text\n",
      "0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
      "1          0  is upset that he can't update his Facebook by ...\n",
      "2          0  @Kenichan I dived many times for the ball. Man...\n",
      "3          0    my whole body feels itchy and like its on fire \n",
      "4          0  @nationwideclass no, it's not behaving at all....\n",
      "sentiment\n",
      "0    800000\n",
      "1    800000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df.columns = [\"sentiment\", \"id\", \"date\", \"flag\", \"user\", \"text\"]\n",
    "df = df[[\"sentiment\", \"text\"]]\n",
    "\n",
    "df[\"sentiment\"] = df[\"sentiment\"].replace({4:1})\n",
    "\n",
    "print(df.head())\n",
    "print(df[\"sentiment\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73994a60",
   "metadata": {},
   "source": [
    "Now we can split the data into train, validation, and test using stratified sampling to ensure fair evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f62d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment\n",
      "0    800000\n",
      "1    800000\n",
      "Name: count, dtype: int64\n",
      "sentiment\n",
      "1    791281\n",
      "0    790185\n",
      "Name: count, dtype: int64\n",
      "train split: 1138655\n",
      "validation split: 284664\n",
      "test split: 158147\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print (df[\"sentiment\"].value_counts())\n",
    "df = df.drop_duplicates(subset=\"text\")\n",
    "print (df[\"sentiment\"].value_counts())\n",
    "\n",
    "# Split into train&val (90%) and the test set (10%)\n",
    "train_val_texts, test_texts, train_val_labels, test_labels = train_test_split(df[\"text\"].values, df[\"sentiment\"].values, test_size=0.1, random_state=1)\n",
    "\n",
    "# Now split train&val into train (90% of 90% --> 81%) and val (10% of 90% --> 9%)\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(train_val_texts, train_val_labels, test_size=0.2, random_state=1)\n",
    "\n",
    "print(f\"train split: {train_texts.shape[0]}\")\n",
    "print(f\"validation split: {val_texts.shape[0]}\")\n",
    "print(f\"test split: {test_texts.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54261864",
   "metadata": {},
   "source": [
    "We will vectorize text at the beginning of our ML approach and tokenize at the start of our DL approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bc3609",
   "metadata": {},
   "source": [
    "---\n",
    "### 2. Classical ML Approach ðŸ’»\n",
    "\n",
    "#### Steps ðŸ“„:\n",
    "- Extract features with TF-IDF\n",
    "\n",
    "- Train logistic regression model\n",
    "\n",
    "- Evaluate model on validation and test set\n",
    "\n",
    "- Analyze performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bce7dcc",
   "metadata": {},
   "source": [
    "We will start our ML approach by vectorizing our text data and fitting our model to the train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "5ddc8e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=15000)\n",
    "\n",
    "# These will be the features for our ML model, we fit on our training features\n",
    "ml_X_train = vectorizer.fit_transform(train_texts)\n",
    "ml_X_val = vectorizer.transform(val_texts)\n",
    "ml_X_test = vectorizer.transform(test_texts)\n",
    "\n",
    "# The labels for our ML model\n",
    "ml_y_train = train_labels\n",
    "ml_y_val = val_labels\n",
    "ml_y_test = test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52135809",
   "metadata": {},
   "source": [
    "Now we can take a look at the first 10 words inside the internal feature matrix and their respective IDF scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "ce8ae01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 words: ['snuggled', 'in', 'on', 'the', 'couch', 'with', 'got', 'player', 'so', 'finally']\n",
      "IDF Scores: [ 8.25079712  8.47301288 10.3603917  10.50270792 10.41275968 10.26322795\n",
      " 10.50270792  9.90840658  9.95492659  9.5887729 ]\n"
     ]
    }
   ],
   "source": [
    "print (f\"First 10 words: {list(vectorizer.vocabulary_.keys())[:10]}\")\n",
    "print (f\"IDF Scores: {vectorizer.idf_[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5fbcb7",
   "metadata": {},
   "source": [
    "Next we'll initialize and train a logistic regression model on our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "015fdfdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('penalty',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">penalty&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;l2&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('dual',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">dual&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tol&nbsp;</td>\n",
       "            <td class=\"value\">0.0001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('C',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">C&nbsp;</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">fit_intercept&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('intercept_scaling',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">intercept_scaling&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">class_weight&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('solver',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">solver&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;lbfgs&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_iter&nbsp;</td>\n",
       "            <td class=\"value\">1000</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('multi_class',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">multi_class&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;deprecated&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">warm_start&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('l1_ratio',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">l1_ratio&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(ml_X_train, ml_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be541c7b",
   "metadata": {},
   "source": [
    "Now lets get a baseline to see how our model performs on its training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "c2c993e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.8026557649156242\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "ml_train_preds = clf.predict(ml_X_train)\n",
    "\n",
    "print (f\"Training Accuracy: {accuracy_score(ml_y_train, ml_train_preds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a65eef8",
   "metadata": {},
   "source": [
    "Our training accuracy is good, 75-80% is a nice range to fall in for this model on this dataset. We're just going to be using this model as a baseline to compare against our DL model so we don't necessarily need to fine tune the hyperparameters (unless we see an issue). Before we evaluate on our test set, though, lets check our validation accuracy to make sure the model isn't overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "755047c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7956011297529719\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.78      0.79    142442\n",
      "           1       0.79      0.81      0.80    142222\n",
      "\n",
      "    accuracy                           0.80    284664\n",
      "   macro avg       0.80      0.80      0.80    284664\n",
      "weighted avg       0.80      0.80      0.80    284664\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "ml_val_preds = clf.predict(ml_X_val)\n",
    "\n",
    "print (f\"Validation Accuracy: {accuracy_score(ml_y_val, ml_val_preds)}\")\n",
    "print (classification_report(ml_y_val, ml_val_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3616c9e9",
   "metadata": {},
   "source": [
    "Nice, it looks like the model isn't overfitting and is doing well at generalizing to our validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f96a85",
   "metadata": {},
   "source": [
    "Now lets evaluate the model's performance on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "f3b09b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7970116410681202\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.78      0.79     79036\n",
      "           1       0.79      0.81      0.80     79111\n",
      "\n",
      "    accuracy                           0.80    158147\n",
      "   macro avg       0.80      0.80      0.80    158147\n",
      "weighted avg       0.80      0.80      0.80    158147\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ml_test_preds = clf.predict(ml_X_test)\n",
    "\n",
    "print (f\"Test Accuracy: {accuracy_score(ml_y_test, ml_test_preds)}\")\n",
    "print (classification_report(ml_y_test, ml_test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1862b405",
   "metadata": {},
   "source": [
    "Great, around 79% accuracy is a nice baseline to compare to moving fowards. Now we can move to our DL approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4682b6f",
   "metadata": {},
   "source": [
    "---\n",
    "### 3. Deep Learning Approach ðŸ§ \n",
    "\n",
    "#### Steps ðŸ“„:\n",
    "- Tokenize and vectorize features\n",
    "\n",
    "- Create dataset and dataloaders\n",
    "\n",
    "- Build and train LSTM model\n",
    "\n",
    "- Test on validation and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82635ce9",
   "metadata": {},
   "source": [
    "Lets start by building our vocabulary which includes tokenization and numericalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "9c98bb7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 92569\n",
      "First 3 words: snuggled, in, on\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from collections import Counter\n",
    "\n",
    "class Vocabulary:\n",
    "    def __init__(self, min_freq=5):\n",
    "        self.min_freq = min_freq\n",
    "        self.word2idx = {\"<pad>\": 0, \"<unk>\": 1}\n",
    "        self.idx2word = {0: \"<pad>\", 1: \"<unk>\"}\n",
    "        self.idx = 2\n",
    "    \n",
    "    # Build vocabulary, updating word2idx and idx2word with words that appear >= min_freq\n",
    "    def build_vocab(self, tweets):\n",
    "        counter = Counter()\n",
    "        for tweet in tweets:\n",
    "            counter.update(tweet.lower().split())\n",
    "\n",
    "        for word, count in counter.items():\n",
    "            if count>= self.min_freq and word not in self.word2idx:\n",
    "                self.word2idx[word] = self.idx\n",
    "                self.idx2word[self.idx] = word\n",
    "                self.idx+= 1\n",
    "    \n",
    "    # Convert a given tweet to indexes\n",
    "    def numericalize(self, tweet):\n",
    "        tokens = tweet.lower().split()\n",
    "        return [self.word2idx.get(token, self.word2idx[\"<unk>\"]) for token in tokens]\n",
    "\n",
    "# Build vocab\n",
    "vocab = Vocabulary()\n",
    "#vocab.build_vocab(df_train[\"text\"])\n",
    "\n",
    "\n",
    "vocab.build_vocab(train_texts)\n",
    "\n",
    "# Check\n",
    "print (f\"Vocab size: {len(vocab.word2idx)}\")\n",
    "print (f\"First 3 words: {vocab.idx2word[2]}, {vocab.idx2word[3]}, {vocab.idx2word[4]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d09b5a",
   "metadata": {},
   "source": [
    "Great, now lets create our `Dataset` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "7acf7d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "# PyTorch Dataset for our DataLoaders\n",
    "class TweetDataset(Dataset):\n",
    "    def __init__(self, tweets, sentiments, vocab, max_len=100):\n",
    "        self.tweets = tweets\n",
    "        self.sentiments = sentiments\n",
    "        self.vocab = vocab\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.tweets)\n",
    "    \n",
    "    # Convert to numerical tokens and return feature and label as tensor pair\n",
    "    def __getitem__(self, index):\n",
    "        text = self.tweets[index]\n",
    "        label = self.sentiments[index]\n",
    "\n",
    "        # Convert text to numericalized tokens\n",
    "        numericalized = self.vocab.numericalize(text)\n",
    "        \n",
    "        return (\n",
    "            torch.tensor(numericalized, dtype=torch.long),\n",
    "            torch.tensor(label, dtype=torch.float)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7956fcc",
   "metadata": {},
   "source": [
    "Next lets make the collate function for our DataLoaders to pad our texts and batch our features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "e922aaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate(batch):\n",
    "    texts, labels = zip(*batch)\n",
    "\n",
    "    # pads tweets to same length and returns as a stacked tensor (batch size, longest tweet)\n",
    "    padded_texts = pad_sequence(texts, batch_first=True, padding_value=0)\n",
    "\n",
    "    # stacks labels into tensor\n",
    "    labels = torch.stack(labels)\n",
    "\n",
    "    return padded_texts, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180e438f",
   "metadata": {},
   "source": [
    "Now lets make the `DataLoaders` for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "6d001601",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "max_len = 100\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "# Creates datasets\n",
    "test_dataset = TweetDataset(test_texts.tolist(), test_labels.tolist(), vocab, max_len)\n",
    "train_dataset = TweetDataset(train_texts.tolist(), train_labels.tolist(), vocab, max_len)\n",
    "val_dataset = TweetDataset(val_texts.tolist(), val_labels.tolist(), vocab, max_len)\n",
    "    \n",
    "# Wraps datasets in DataLoaders and shuffles training dataset\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbcf7f5",
   "metadata": {},
   "source": [
    "Before we move to building the model, lets verify our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "eb423214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 1138655\n",
      "Validation samples: 284664\n",
      "Test samples: 158147\n",
      "Raw sample text: Snuggled in on the couch with Dex.. I got a divex player so I'm finally watching season 1 of True Blood @wallybertone sent me   xox\n",
      "Processed sample text: tensor([ 2,  3,  4,  5,  6,  7,  1,  8,  9, 10,  1, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20,  1, 21, 22, 23])\n",
      "Sample label: 1.0\n",
      "Texts tensor shape: torch.Size([64, 29])\n",
      "Labels tensor shape: torch.Size([64])\n",
      "First text in batch: just got home from school, done my science exam, gonna catch up on some <unk> didn't sleep well last night\n",
      "First label in batch: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Check our dataset lengths\n",
    "print (f\"Training samples: {len(train_dataset)}\")\n",
    "print (f\"Validation samples: {len(val_dataset)}\")\n",
    "print (f\"Test samples: {len(test_dataset)}\")\n",
    "\n",
    "# Check the first training sample\n",
    "text, sentiment = train_dataset[0]\n",
    "print (f\"Raw sample text: {train_texts[0]}\")\n",
    "print (f\"Processed sample text: {text}\")\n",
    "print (f\"Sample label: {sentiment}\")\n",
    "\n",
    "# Check batch shapes\n",
    "batch_texts, batch_sentiments = next(iter(train_loader))\n",
    "print (f\"Texts tensor shape: {batch_texts.shape}\")\n",
    "print (f\"Labels tensor shape: {batch_sentiments.shape}\")\n",
    "\n",
    "#Check batch content\n",
    "first_text = [vocab.idx2word[i] for i in (batch_texts[0].tolist()) if i != vocab.word2idx[\"<pad>\"]]\n",
    "print (f\"First text in batch: {' '.join(first_text)}\")\n",
    "print (f\"First label in batch: {batch_sentiments[0].item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29902a73",
   "metadata": {},
   "source": [
    "Great, our datasets look good and our DataLoaders appear to be working. <br/>\n",
    "Feature tensors are the right shape (labels as well) and padding looks to be working."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e70f25",
   "metadata": {},
   "source": [
    "Now lets move foward with making our LSTM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "26adf3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "      \n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, pad_index, dropout_rate):\n",
    "        super().__init__()\n",
    "        # Embedding layer: converts tweets (stored as vocab indexes) to dense embedded vectors\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, pad_index)\n",
    "        nn.init.uniform_(self.embedding.weight, -0.05, 0.05)\n",
    "        # LSTM layer: processes embedded input, learning sequential patterns\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        # Dropout layer: drops out percentage of neurons for regularization\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        # Fully connected layer: takes final hidden state from LSTM and converts to output classes\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        lstm_out, _ = self.lstm(embedded)\n",
    "        \n",
    "        last_state = self.dropout(lstm_out[:, -1, :])\n",
    "        return self.fc(last_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65347b9b",
   "metadata": {},
   "source": [
    "With our layers and forward pass defined, lets move on to defining our hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "d765edd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = LSTMClassifier(\n",
    "    vocab_size=len(vocab.word2idx),\n",
    "    embedding_dim = 100,\n",
    "    hidden_dim = 128,\n",
    "    output_dim = 1,\n",
    "    pad_index = 0,\n",
    "    dropout_rate = 0.5\n",
    ").to(device)\n",
    "\n",
    "# We are using BCE for our loss function to classify our logits from the FC layer w/ softmax \n",
    "# Adam is a good, simple optimizer for NLP tasks, especially when using LSTMs like this model\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58ffcff",
   "metadata": {},
   "source": [
    "With our model defined, lets build the training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "5916a727",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, iterator, optimizer, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    batches = len(iterator)\n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, batch in enumerate(iterator):\n",
    "        optimizer.zero_grad()\n",
    "        texts, labels = batch\n",
    "        texts, labels = texts.to(device), labels.to(device)\n",
    "        \n",
    "        predictions = model(texts).squeeze(1)\n",
    "        loss = criterion(predictions, labels)\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        rounded_preds = torch.round(torch.sigmoid(predictions))\n",
    "        correct = (rounded_preds == labels).float()\n",
    "        acc = correct.sum() / len(correct)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        print(f\"Processing batch {batch_idx + 1}/{batches}\", end='\\r')\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70933c3f",
   "metadata": {},
   "source": [
    "Next, lets make our evaluation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "21e37177",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            texts, labels = batch\n",
    "            texts, labels = texts.to(device), labels.to(device)\n",
    "            \n",
    "            predictions = model(texts).squeeze(1)\n",
    "            loss = criterion(predictions, labels)\n",
    "            \n",
    "            rounded_preds = torch.round(torch.sigmoid(predictions))\n",
    "            correct = (rounded_preds == labels).float()\n",
    "            acc = correct.sum() / len(correct)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27425c3b",
   "metadata": {},
   "source": [
    "To get our best model and prevent overfitting, lets implement a simple early stopping class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "d5c969ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=2, delta=0, verbose=False):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.stop_early = False\n",
    "        self.min_loss = np.Inf\n",
    "        self.best_state = None\n",
    "        \n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f\"Early Stop counter: {self.counter}/{self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.stop_early = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "    \n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        if self.verbose:\n",
    "            print(f\"Validation loss improved ({self.min_loss} -> {val_loss})\")\n",
    "        self.best_state = {k: v.clone() for k, v in model.state_dict().items()}\n",
    "        self.min_loss = val_loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "63d77391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0+cu118\n",
      "True\n",
      "Epoch 1: Training Acc = 0.790 | Val Acc = 0.821 | Training Loss = 0.442| Val Loss = 0.396\n",
      "Epoch 2: Training Acc = 0.842 | Val Acc = 0.827 | Training Loss = 0.358| Val Loss = 0.386\n",
      "Epoch 3: Training Acc = 0.865 | Val Acc = 0.823 | Training Loss = 0.315| Val Loss = 0.395\n",
      "Early stopping triggered\n"
     ]
    }
   ],
   "source": [
    "print (torch.__version__)\n",
    "print (torch.cuda.is_available())\n",
    "\n",
    "early_stopping = EarlyStopping(patience=1, verbose=False)\n",
    "\n",
    "for epoch in range(10):\n",
    "    train_loss, train_acc = train_loop(model, train_loader, optimizer=optimizer, criterion=criterion)\n",
    "    val_loss, val_acc = evaluate(model, val_loader, criterion=criterion)\n",
    "    print (f\"Epoch {epoch+1}: Training Acc = {train_acc:.3f} | Val Acc = {val_acc:.3f} | Training Loss = {train_loss:.3f}| Val Loss = {val_loss:.3f}\")\n",
    "    \n",
    "    early_stopping(val_loss, model)\n",
    "    if early_stopping.stop_early:\n",
    "        print (\"Early stopping triggered\")\n",
    "        break\n",
    "\n",
    "if early_stopping.best_state is not None:\n",
    "    model.load_state_dict(early_stopping.best_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "3a6e6b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss = 0.3861074270831246 | Test Acc = 0.8255713996763754\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate(model, test_loader, criterion=criterion)\n",
    "print (f\"Test loss = {test_loss} | Test Acc = {test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6742d1e",
   "metadata": {},
   "source": [
    "Awesome, ~82% is a great accuracy and it's nice to see our LSTM is doing better than the traditional LR model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac307585",
   "metadata": {},
   "source": [
    "### 4. Comparisons and Conclusions ðŸ’­"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bae8349",
   "metadata": {},
   "source": [
    "To compare our two models (ML and DL), lets start by comparing their standard metrics (F1 score, accuracy/loss, ROC curve)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817d45f7",
   "metadata": {},
   "source": [
    "#### F1 score, recall, and precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "aac3e0a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML (LR) Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.78      0.79     79036\n",
      "           1       0.79      0.81      0.80     79111\n",
      "\n",
      "    accuracy                           0.80    158147\n",
      "   macro avg       0.80      0.80      0.80    158147\n",
      "weighted avg       0.80      0.80      0.80    158147\n",
      "\n",
      "DL (LSTM) Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82     79036\n",
      "           1       0.82      0.83      0.83     79111\n",
      "\n",
      "    accuracy                           0.83    158147\n",
      "   macro avg       0.83      0.83      0.83    158147\n",
      "weighted avg       0.83      0.83      0.83    158147\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression model\n",
    "ml_preds = clf.predict(vectorizer.transform(test_texts))\n",
    "\n",
    "# LSTM model\n",
    "model.eval()\n",
    "dl_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        texts, labels = batch\n",
    "        texts = texts.to(next(model.parameters()).device)\n",
    "        output = model(texts)\n",
    "        \n",
    "        probs = torch.sigmoid(output).squeeze()\n",
    "        preds = (probs >= 0.5).int()\n",
    "        \n",
    "        dl_preds.extend(preds.cpu().numpy())\n",
    "dl_preds = np.array(dl_preds)\n",
    "                        \n",
    "#Create classification reports\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"ML (LR) Report:\\n\", classification_report(test_labels, ml_preds))\n",
    "print(\"DL (LSTM) Report:\\n\", classification_report(test_labels, dl_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823e6bf7",
   "metadata": {},
   "source": [
    "Nice! Looks, like both models perform well with the LSTM model just barely edging out the LR model by a percentage point.<br>\n",
    "Now lets plot each model's ROC curve along with their AUCs to gain insight into the TPR v.s. FPR across every threshold."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-nlp (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
