{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac64f10c",
   "metadata": {},
   "source": [
    "# Twitter NLP Sentiment Classifier\n",
    "\n",
    "This notebook builds a simple NLP model to classify tweets as positive, neutral, or negative using the [Twitter140 dataset](https://www.kaggle.com/datasets/kazanova/sentiment140)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0155e82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import basic core libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d080874a",
   "metadata": {},
   "source": [
    "---\n",
    "### 1. Data Preprocessing ðŸ”¨\n",
    "\n",
    "#### Steps ðŸ“„:\n",
    "- Load and inspect Sentiment140 dataset\n",
    "\n",
    "- Clean raw tweet text\n",
    "\n",
    "- Normalize case and remove stopwords\n",
    "\n",
    "- Split into training, validation, and testing sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340513be",
   "metadata": {},
   "source": [
    "We'll begin by loading our dataframe and exploring the dataset to get an understanding of its structure and the distribution of sentiment labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "164a744d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0           1                             2         3                4  \\\n",
      "0  0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY  _TheSpecialOne_   \n",
      "1  0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY    scotthamilton   \n",
      "2  0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY         mattycus   \n",
      "3  0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          ElleCTF   \n",
      "4  0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY           Karoli   \n",
      "\n",
      "                                                   5  \n",
      "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
      "1  is upset that he can't update his Facebook by ...  \n",
      "2  @Kenichan I dived many times for the ball. Man...  \n",
      "3    my whole body feels itchy and like its on fire   \n",
      "4  @nationwideclass no, it's not behaving at all....  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0\n",
       "0    800000\n",
       "4    800000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/Sentiment140.csv\", encoding=\"latin-1\", header=None)\n",
    "\n",
    "print(df.head())\n",
    "df[0].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657516a6",
   "metadata": {},
   "source": [
    "We are only going to be using the sentiment and text, which are found in column 1 and 5 respectively.<br/>\n",
    "The sentiment is distributed evenly between 0 (negative) and 4 (positive).<br/>\n",
    "It is also clear that the text will need some cleaning (tags, urls, special characters, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce3302c",
   "metadata": {},
   "source": [
    "Lets label our columns and grab the ones we want. <br/>\n",
    "We'll also map all 4s to 1 for binary simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64caf399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sentiment                                               text\n",
      "0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
      "1          0  is upset that he can't update his Facebook by ...\n",
      "2          0  @Kenichan I dived many times for the ball. Man...\n",
      "3          0    my whole body feels itchy and like its on fire \n",
      "4          0  @nationwideclass no, it's not behaving at all....\n",
      "sentiment\n",
      "0    800000\n",
      "1    800000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df.columns = [\"sentiment\", \"id\", \"date\", \"flag\", \"user\", \"text\"]\n",
    "df = df[[\"sentiment\", \"text\"]]\n",
    "\n",
    "df[\"sentiment\"] = df[\"sentiment\"].replace({4:1})\n",
    "\n",
    "print(df.head())\n",
    "print(df[\"sentiment\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf91ea8",
   "metadata": {},
   "source": [
    "Next we'll use the `regular expressions` module and `NLTK` library to clean the tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90fcaf54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\theli\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        thats bummer shoulda got david carr third day\n",
      "1    upset cant update facebook texting might cry r...\n",
      "2    dived many times ball managed save rest go bounds\n",
      "3                     whole body feels itchy like fire\n",
      "4                             behaving im mad cant see\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "# We are removing urls, tags (@), hashtags, and special characters from the tweets\n",
    "# We also remove stopwords, words that contrubute very little to the sentiment of the tweets (ex. \"the\", \"and\", or \"is\")\n",
    "def clean_tweets(text):\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text)\n",
    "    text = re.sub(r\"@\\w+\", \"\", text)\n",
    "    text = re.sub(r\"#\\w+\", \"\", text)\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)\n",
    "    text = text.lower().strip().split()\n",
    "    text = [word for word in text if word not in stop_words]\n",
    "    return \" \".join(text)\n",
    "\n",
    "df[\"text\"] = df[\"text\"].apply(clean_tweets)\n",
    "print (df[\"text\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25ad4475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    # Keep apostrophes and basic punctuation\n",
    "    text = re.sub(r\"[^a-zA-Z'\\s]\", \"\", text)  # Allow apostrophes\n",
    "    words = text.lower().strip().split()\n",
    "    # Custom stop words - preserve sentiment carriers\n",
    "    custom_stopwords = set(stopwords.words('english')) - {'not', 'no', 'never', 'very'}\n",
    "    return [w for w in words if w not in custom_stopwords]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73994a60",
   "metadata": {},
   "source": [
    "Now we can split the data into train, validation, and test using stratified sampling to ensure fair evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7f62d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment\n",
      "0    800000\n",
      "1    800000\n",
      "Name: count, dtype: int64\n",
      "sentiment\n",
      "0    748482\n",
      "1    731249\n",
      "Name: count, dtype: int64\n",
      "train split: sentiment\n",
      "0    0.504877\n",
      "1    0.495123\n",
      "Name: proportion, dtype: float64\n",
      "validation split: sentiment\n",
      "0    0.504881\n",
      "1    0.495119\n",
      "Name: proportion, dtype: float64\n",
      "test split: sentiment\n",
      "0    0.504866\n",
      "1    0.495134\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print (df[\"sentiment\"].value_counts())\n",
    "#print (df[\"text\"].value_counts())\n",
    "df = df.drop_duplicates(subset=\"text\")\n",
    "print (df[\"sentiment\"].value_counts())\n",
    "#print (df[\"text\"].value_counts())\n",
    "\n",
    "df = df.sample(frac=0.1, random_state=1)  # use only 10% of the full dataset (temporary)\n",
    "\n",
    "# Split into train&val (90%) and the test set (10%)\n",
    "df_trainandval, df_test = train_test_split(df, test_size=0.1, stratify=df[\"sentiment\"], random_state=1)\n",
    "\n",
    "# Now split train&val into train (90% of 90% --> 81%) and val (10% of 90% --> 9%)\n",
    "df_train, df_val = train_test_split(df_trainandval, test_size=0.1, stratify=df_trainandval[\"sentiment\"], random_state=1)\n",
    "\n",
    "print(f\"train split: {df_train['sentiment'].value_counts(normalize=True)}\")\n",
    "print(f\"validation split: {df_val['sentiment'].value_counts(normalize=True)}\")\n",
    "print(f\"test split: {df_test['sentiment'].value_counts(normalize=True)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54261864",
   "metadata": {},
   "source": [
    "We will vectorize text at the beginning of our ML approach and tokenize at the start of our DL approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bc3609",
   "metadata": {},
   "source": [
    "---\n",
    "### 2. Classical ML Approach ðŸ’»\n",
    "\n",
    "#### Steps ðŸ“„:\n",
    "- Extract features with TF-IDF\n",
    "\n",
    "- Train logistic regression model\n",
    "\n",
    "- Evaluate model on validation and test set\n",
    "\n",
    "- Analyze performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bce7dcc",
   "metadata": {},
   "source": [
    "We will start our ML approach by vectorizing our text data and fitting our model to the train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5ddc8e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=15000)\n",
    "\n",
    "# These will be the features for our ML model, we fit on our training features\n",
    "ml_X_train = vectorizer.fit_transform(df_train[\"text\"])\n",
    "ml_X_val = vectorizer.transform(df_val[\"text\"])\n",
    "ml_X_test = vectorizer.transform(df_test[\"text\"])\n",
    "\n",
    "# The labels for our ML model\n",
    "ml_y_train = df_train[\"sentiment\"]\n",
    "ml_y_val = df_val[\"sentiment\"]\n",
    "ml_y_test = df_test[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52135809",
   "metadata": {},
   "source": [
    "Now we can take a look at the first 10 words inside the internal feature matrix and their respective IDF scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ce8ae01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 words: ['studying', 'dates', 'suck', 'got', 'all', 'the', 'titles', 'and', 'majority', 'of']\n",
      "IDF Scores: [ 8.2504272   8.20786759 10.37432051 10.28730913 10.82630563 10.13315845\n",
      "  9.8277768  10.06416558  9.55333995 10.13315845]\n"
     ]
    }
   ],
   "source": [
    "print (f\"First 10 words: {list(vectorizer.vocabulary_.keys())[:10]}\")\n",
    "print (f\"IDF Scores: {vectorizer.idf_[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5fbcb7",
   "metadata": {},
   "source": [
    "Next we'll initialize and train a logistic regression model on our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "015fdfdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(ml_X_train, ml_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be541c7b",
   "metadata": {},
   "source": [
    "Now lets get a baseline to see how our model performs on its training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c2c993e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.8028395061728395\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "ml_train_preds = clf.predict(ml_X_train)\n",
    "\n",
    "print (f\"Training Accuracy: {accuracy_score(ml_y_train, ml_train_preds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a65eef8",
   "metadata": {},
   "source": [
    "Our training accuracy is good, 75-80% is a nice range to fall in for this model on this dataset. We're just going to be using this model as a baseline to compare against our DL model so we don't necessarily need to fine tune the hyperparameters (unless we see an issue). Before we evaluate on our test set, though, lets check our validation accuracy to make sure the model isn't overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "755047c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7693055555555556\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.75      0.76      7185\n",
      "           1       0.76      0.79      0.77      7215\n",
      "\n",
      "    accuracy                           0.77     14400\n",
      "   macro avg       0.77      0.77      0.77     14400\n",
      "weighted avg       0.77      0.77      0.77     14400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "ml_val_preds = clf.predict(ml_X_val)\n",
    "\n",
    "print (f\"Validation Accuracy: {accuracy_score(ml_y_val, ml_val_preds)}\")\n",
    "print (classification_report(ml_y_val, ml_val_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3616c9e9",
   "metadata": {},
   "source": [
    "Nice, it looks like the model isn't overfitting and is doing well at generalizing to our validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f96a85",
   "metadata": {},
   "source": [
    "Now lets evaluate the model's performance on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f3b09b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7698125\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.76      0.77      7984\n",
      "           1       0.76      0.78      0.77      8016\n",
      "\n",
      "    accuracy                           0.77     16000\n",
      "   macro avg       0.77      0.77      0.77     16000\n",
      "weighted avg       0.77      0.77      0.77     16000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ml_test_preds = clf.predict(ml_X_test)\n",
    "\n",
    "print (f\"Test Accuracy: {accuracy_score(ml_y_test, ml_test_preds)}\")\n",
    "print (classification_report(ml_y_test, ml_test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1862b405",
   "metadata": {},
   "source": [
    "Great, 77% accuracy is a nice baseline to compare to moving fowards. Now we can move to our DL approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4682b6f",
   "metadata": {},
   "source": [
    "---\n",
    "### 3. Deep Learning Approach ðŸ§ \n",
    "\n",
    "#### Steps ðŸ“„:\n",
    "- Tokenize and vectorize features\n",
    "\n",
    "- Create dataset and dataloaders\n",
    "\n",
    "- Build and train LSTM model\n",
    "\n",
    "- Test on validation and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82635ce9",
   "metadata": {},
   "source": [
    "Lets start by building our vocabulary which includes tokenization and numericalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c98bb7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 11747\n",
      "First 3 words: sorry, delayed, response\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from collections import Counter\n",
    "\n",
    "class Vocabulary:\n",
    "    def __init__(self, min_freq=5):\n",
    "        self.min_freq = min_freq\n",
    "        self.word2idx = {\"<pad>\": 0, \"<unk>\": 1}\n",
    "        self.idx2word = {0: \"<pad>\", 1: \"<unk>\"}\n",
    "        self.idx = 2\n",
    "    \n",
    "    # Build vocabulary, updating word2idx and idx2word with words that appear >= min_freq\n",
    "    def build_vocab(self, tweets):\n",
    "        counter = Counter()\n",
    "        for tweet in tweets:\n",
    "            counter.update(tweet.lower().split())\n",
    "\n",
    "        for word, count in counter.items():\n",
    "            if count>= self.min_freq and word not in self.word2idx:\n",
    "                self.word2idx[word] = self.idx\n",
    "                self.idx2word[self.idx] = word\n",
    "                self.idx+= 1\n",
    "    \n",
    "    # Convert a given tweet to indexes\n",
    "    def numericalize(self, tweet):\n",
    "        tokens = tweet.lower().split()\n",
    "        return [self.word2idx.get(token, self.word2idx[\"<unk>\"]) for token in tokens]\n",
    "\n",
    "# Build vocab\n",
    "vocab = Vocabulary()\n",
    "#vocab.build_vocab(df_train[\"text\"])\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(df[\"text\"], df[\"sentiment\"], test_size=0.2, random_state=1)\n",
    "vocab.build_vocab(train_texts)\n",
    "\n",
    "# Check\n",
    "print (f\"Vocab size: {len(vocab.word2idx)}\")\n",
    "print (f\"First 3 words: {vocab.idx2word[2]}, {vocab.idx2word[3]}, {vocab.idx2word[4]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d09b5a",
   "metadata": {},
   "source": [
    "Great, now lets create our `Dataset` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7acf7d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "# PyTorch Dataset for our DataLoaders\n",
    "class TweetDataset(Dataset):\n",
    "    def __init__(self, tweets, sentiments, vocab, max_len=100):\n",
    "        self.tweets = tweets\n",
    "        self.sentiments = sentiments\n",
    "        self.vocab = vocab\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.tweets)\n",
    "    \n",
    "    # Convert to numerical tokens and return feature and label as tensor pair\n",
    "    def __getitem__(self, index):\n",
    "        text = self.tweets[index]\n",
    "        label = self.sentiments[index]\n",
    "\n",
    "        # Convert text to numericalized tokens\n",
    "        numericalized = self.vocab.numericalize(text)\n",
    "        \n",
    "        return (\n",
    "            torch.tensor(numericalized, dtype=torch.long),\n",
    "            torch.tensor(label, dtype=torch.float)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7956fcc",
   "metadata": {},
   "source": [
    "Next lets make the collate function for our DataLoaders to pad our texts and batch our features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e922aaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate(batch):\n",
    "    texts, labels = zip(*batch)\n",
    "\n",
    "    # pads tweets to same length and returns as a stacked tensor (batch size, longest tweet)\n",
    "    padded_texts = pad_sequence(texts, batch_first=True, padding_value=0)\n",
    "\n",
    "    # stacks labels into tensor\n",
    "    labels = torch.stack(labels)\n",
    "\n",
    "    return padded_texts, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180e438f",
   "metadata": {},
   "source": [
    "Now lets make the `DataLoaders` for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d001601",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "max_len = 100\n",
    "batch_size = 64\n",
    "\n",
    "# Creates datasets\n",
    "#train_dataset = TweetDataset(df_train[\"text\"].tolist(), df_train[\"sentiment\"].tolist(), vocab, max_len)\n",
    "#val_dataset = TweetDataset(df_val[\"text\"].tolist(), df_val[\"sentiment\"].tolist(), vocab, max_len)\n",
    "test_dataset = TweetDataset(df_test[\"text\"].tolist(), df_test[\"sentiment\"].tolist(), vocab, max_len)\n",
    "train_dataset = TweetDataset(train_texts.tolist(), train_labels.tolist(), vocab, max_len)\n",
    "val_dataset = TweetDataset(test_texts.tolist(), test_labels.tolist(), vocab, max_len)\n",
    "    \n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, \n",
    "                             shuffle=True, collate_fn=collate)\n",
    "val_loader = DataLoader(test_dataset, batch_size=batch_size, \n",
    "                            shuffle=False, collate_fn=collate)\n",
    "# Wraps datasets in DataLoaders and shuffles training dataset\n",
    "#train_loader = DataLoader(train_dataset, batch_size, shuffle=True, collate_fn=collate)\n",
    "#val_loader = DataLoader(val_dataset, batch_size, shuffle=False, collate_fn=collate)\n",
    "test_loader = DataLoader(test_dataset, batch_size, shuffle=False, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbcf7f5",
   "metadata": {},
   "source": [
    "Before we move to building the model, lets verify our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb423214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 118378\n",
      "Validation samples: 29595\n",
      "Test samples: 14798\n",
      "Raw sample text: tweet lost\n",
      "Processed sample text: tensor([ 2,  3,  4,  5,  1,  6,  7,  8,  9, 10, 11])\n",
      "Sample label: 0.0\n",
      "Texts tensor shape: torch.Size([64, 15])\n",
      "Labels tensor shape: torch.Size([64])\n",
      "First text in batch: wait til hear rob pattinson sing uhhh <unk> serious <unk> alright <unk>\n",
      "First label in batch: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Check our dataset lengths\n",
    "print (f\"Training samples: {len(train_dataset)}\")\n",
    "print (f\"Validation samples: {len(val_dataset)}\")\n",
    "print (f\"Test samples: {len(test_dataset)}\")\n",
    "\n",
    "# Check the first training sample\n",
    "text, sentiment = train_dataset[0]\n",
    "print (f\"Raw sample text: {df_train['text'].iloc[0]}\")\n",
    "print (f\"Processed sample text: {text}\")\n",
    "print (f\"Sample label: {sentiment}\")\n",
    "\n",
    "# Check batch shapes\n",
    "batch_texts, batch_sentiments = next(iter(train_loader))\n",
    "print (f\"Texts tensor shape: {batch_texts.shape}\")\n",
    "print (f\"Labels tensor shape: {batch_sentiments.shape}\")\n",
    "\n",
    "#Check batch content\n",
    "first_text = [vocab.idx2word[i] for i in (batch_texts[0].tolist()) if i != vocab.word2idx[\"<pad>\"]]\n",
    "print (f\"First text in batch: {' '.join(first_text)}\")\n",
    "print (f\"First label in batch: {batch_sentiments[0].item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29902a73",
   "metadata": {},
   "source": [
    "Great, our datasets look good and our DataLoaders appear to be working. <br/>\n",
    "Feature tensors are the right shape (labels as well) and padding looks to be working."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e70f25",
   "metadata": {},
   "source": [
    "Now lets move foward with making our LSTM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26adf3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "      \n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, pad_index, dropout_rate):\n",
    "        super().__init__()\n",
    "        # Embedding layer: converts tweets (stored as vocab indexes) to dense embedded vectors\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, pad_index)\n",
    "        nn.init.uniform_(self.embedding.weight, -0.05, 0.05)\n",
    "        # LSTM layer: processes embedded input, learning sequential patterns\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        # Dropout layer: drops out percentage of neurons for regularization\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        # Fully connected layer: takes final hidden state from LSTM and converts to output classes\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        lstm_out, _ = self.lstm(embedded)\n",
    "        \n",
    "        last_state = self.dropout(lstm_out[:, -1, :])\n",
    "        return self.fc(last_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65347b9b",
   "metadata": {},
   "source": [
    "With our layers and forward pass defined, lets move on to defining our hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d765edd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = LSTMClassifier(\n",
    "    vocab_size=len(vocab.word2idx),\n",
    "    embedding_dim = 100,\n",
    "    hidden_dim = 256,\n",
    "    output_dim = 1,\n",
    "    pad_index = 0,\n",
    "    dropout_rate = 0.5\n",
    ").to(device)\n",
    "\n",
    "# We are using BCE for our loss function to classify our logits from the FC layer w/ softmax \n",
    "# Adam is a good, simple optimizer for NLP tasks, especially when using LSTMs like this model\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58ffcff",
   "metadata": {},
   "source": [
    "With our model defined, lets build the training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5916a727",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, iterator):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    batches = len(iterator)\n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, batch in enumerate(iterator):\n",
    "        optimizer.zero_grad()\n",
    "        texts, labels = batch\n",
    "        texts, labels = texts.to(device), labels.to(device)\n",
    "        \n",
    "        predictions = model(texts).squeeze(1)\n",
    "        loss = criterion(predictions, labels)\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        rounded_preds = torch.round(torch.sigmoid(predictions))\n",
    "        correct = (rounded_preds == labels).float()\n",
    "        acc = correct.sum() / len(correct)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        print(f\"Processing batch {batch_idx + 1}/{batches}\", end='\\r')\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70933c3f",
   "metadata": {},
   "source": [
    "Next, lets make our evaluation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21e37177",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            texts, labels = batch\n",
    "            texts, labels = texts.to(device), labels.to(device)\n",
    "            \n",
    "            predictions = model(texts).squeeze(1)\n",
    "            loss = criterion(predictions, labels)\n",
    "            \n",
    "            rounded_preds = torch.round(torch.sigmoid(predictions))\n",
    "            correct = (rounded_preds == labels).float()\n",
    "            acc = correct.sum() / len(correct)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63d77391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0+cu118\n",
      "True\n",
      "11.8\n",
      "Overlap: 0\n",
      "Epoch 1: Training Acc = 0.726281772851944 | Val Acc = 0.7934690580285829 | Training Loss = 0.5347615146636963| Val Loss = 0.4461599515172942\n",
      "Epoch 2: Training Acc = 0.7868194980879087 | Val Acc = 0.8077470752699621 | Training Loss = 0.45774676300383904| Val Loss = 0.4201616828554663\n",
      "Epoch 3: Training Acc = 0.8032251447922475 | Val Acc = 0.8201008315744072 | Training Loss = 0.42355592462662106| Val Loss = 0.4009446560822684\n",
      "Epoch 4: Training Acc = 0.8192507239612373 | Val Acc = 0.8308766936433727 | Training Loss = 0.39191481665985006| Val Loss = 0.3822268681151086\n",
      "Epoch 5: Training Acc = 0.8357380148204597 | Val Acc = 0.8423260470916485 | Training Loss = 0.3589323350303882| Val Loss = 0.3594742101328126\n",
      "Epoch 6: Training Acc = 0.8546400418474868 | Val Acc = 0.8546509393330278 | Training Loss = 0.3243649388084541| Val Loss = 0.34300552604013473\n",
      "Epoch 7: Training Acc = 0.8715866312787339 | Val Acc = 0.8636757238157864 | Training Loss = 0.28851353252658973| Val Loss = 0.33299280054353436\n",
      "Epoch 8: Training Acc = 0.8866755148204597 | Val Acc = 0.8741244612068966 | Training Loss = 0.25757651582763| Val Loss = 0.3286854471240578\n",
      "Epoch 9: Training Acc = 0.8987234556030582 | Val Acc = 0.882745150862069 | Training Loss = 0.23046566389299727| Val Loss = 0.3173352741989596\n",
      "Epoch 10: Training Acc = 0.9095555823880273 | Val Acc = 0.8908270474137931 | Training Loss = 0.20701139261996424| Val Loss = 0.3221876744245147\n"
     ]
    }
   ],
   "source": [
    "print (torch.__version__)\n",
    "print (torch.cuda.is_available())\n",
    "print (torch.version.cuda)\n",
    "\n",
    "overlap = set(df_train['text']) & set(df_val['text'])\n",
    "print(f'Overlap: {len(overlap)}')\n",
    "\n",
    "\n",
    "for epoch in range(10):\n",
    "    train_loss, train_acc = train_loop(model, train_loader)\n",
    "    val_loss, val_acc = evaluate(model, val_loader, criterion=criterion)\n",
    "    print (f\"Epoch {epoch+1}: Training Acc = {train_acc} | Val Acc = {val_acc} | Training Loss = {train_loss}| Val Loss = {val_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac307585",
   "metadata": {},
   "source": [
    "### 4. Comparisons and Conclusions ðŸ’­"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-nlp (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
